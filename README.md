# Human-to-Cartoon Image Translation using CycleGAN

This project implements a **Human-to-Cartoon Image Translation** model using **CycleGAN**, allowing automatic transformation of human portraits into cartoon-style images while preserving essential facial features.

## üöÄ Project Overview

- **Goal:** Convert human images into cartoon-style images while maintaining facial features.
- **Methodology:** Utilizes an unpaired image-to-image translation approach using CycleGAN.
- **Key Features:**
  - **Unpaired Data Handling**: Overcomes the challenge of unpaired datasets using cycle consistency loss.
  - **Generator & Discriminator Networks**: Implements separate networks for both human-to-cartoon and cartoon-to-human transformations.
  - **Optimization Techniques**: Incorporates mixed-precision training and Adam optimizers for efficient learning.

## üìå Table of Contents

- [Introduction](#introduction)
- [Dataset](#dataset)
- [Architecture](#architecture)
- [Training](#training)
- [Results](#results)
- [Installation & Usage](#installation--usage)
- [Challenges & Limitations](#challenges--limitations)
- [References](#references)

---

## üìö Introduction

**Image-to-Image Translation** refers to the task of transforming an image from one domain to another while preserving its content.  
This project aims to **convert real human faces into cartoon-style images** using **CycleGAN**.

### Why CycleGAN?

- Traditional GANs require **paired datasets** (where each input image has a corresponding output), which is often unavailable for human-to-cartoon translation.
- **CycleGAN** overcomes this by using **unpaired datasets** and cycle consistency loss, ensuring that a transformed image can be mapped back to its original domain.

## üìä Dataset

This project uses two datasets:

1. **CartoonSet**: A collection of 2D cartoon avatars with different artistic styles.
   - 500 images for training
   - 10 images for testing
2. **Human Dataset**: **Face Mask Lite Dataset** from Kaggle, containing real human face images.
   - 500 images without masks for training
   - 10 images for testing

### Data Preprocessing:

- **White Background Removal**: Ensures consistency with transparent cartoon backgrounds.
- **Glasses Removal**: Prevents inconsistencies in translation.
- **Front-Facing Image Selection**: Uses only front-facing images to improve accuracy.

## üè∞ Architecture

CycleGAN consists of:

- **Generator A (Human ‚Üí Cartoon)**: Converts human images into cartoon-style images.
- **Generator B (Cartoon ‚Üí Human)**: Converts cartoon images back into human-like images.
- **Discriminator A & B**: Distinguish real human/cartoon images from generated ones.
- **Cycle Consistency Loss**: Ensures that transformations are reversible while preserving identity.

### Model Enhancements:

- **Reduced Residual Blocks**: Uses 4 instead of 6 to improve training speed.
- **No Learning Rate Scheduler**: Simplifies model training.
- **Mixed-Precision Training**: Uses gradient scaling for efficient GPU memory utilization.

## üéØ Training

- **Optimizer:** Adam (LR: 0.0002, Betas: (0.5, 0.999))
- **Loss Functions:**
  - **GAN Loss**: Measures the realism of generated images.
  - **Cycle Consistency Loss**: Ensures reversibility of transformations.
  - **Identity Loss**: Preserves key features in transformations.
- **Training Setup:**
  - Runs for **30 epochs** with a batch size of **1**.
  - Saves the best model checkpoint based on **generator loss**.

## üî• Results

- The model successfully generates **cartoonized human faces** while maintaining facial features.
- Below is a sample output:

  ![Sample Output](./output/final_30_nlr_6rb.png)

## üõ† Installation & Usage

### Prerequisites:

- Python 3.8+
- PyTorch
- torchvision
- Pillow
- tqdm
- matplotlib

### Installation:

```bash
git clone https://github.com/hritiksauw199/Human-to-Cartoon-using-CycleGAN.git
cd Human-to-Cartoon-using-CycleGAN
pip install -r requirements.txt
```

### Running the Model:

```bash
python cyclegan.py
```

## ‚ö†Ô∏è Challenges & Limitations

- **Unpaired Data**: No direct mapping between human and cartoon images.
- **Preserving Details**: Balancing stylization while maintaining identity.
- **Training Time**: Takes **4-5 hours per 50 epochs** on a 4GB GPU.
- **Glasses & Accessories**: Faces with glasses sometimes cause inconsistencies.

## üìö References

- [CycleGAN Paper](https://arxiv.org/pdf/1703.10593)
- [CycleGAN GitHub](https://github.com/junyanz/CycleGAN)
- [Face2Anime CycleGAN](https://github.com/lmtri1998/Face2Anime-using-CycleGAN)

## üìå Authors

This project was developed by:

- **Hritik Sauw**
- **Zabihullah Azimy**
- **Ayushi Chawade**
